{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_slc0gil",
    "id": "1C259CBE4A394E02B3454D9680B0536A",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# è¯åµŒå…¥åŸºç¡€\n",
    "\n",
    "æˆ‘ä»¬åœ¨[â€œå¾ªç¯ç¥ç»ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°â€](https://zh.d2l.ai/chapter_recurrent-neural-networks/rnn-scratch.html)ä¸€èŠ‚ä¸­ä½¿ç”¨ one-hot å‘é‡è¡¨ç¤ºå•è¯ï¼Œè™½ç„¶å®ƒä»¬æ„é€ èµ·æ¥å¾ˆå®¹æ˜“ï¼Œä½†é€šå¸¸å¹¶ä¸æ˜¯ä¸€ä¸ªå¥½é€‰æ‹©ã€‚ä¸€ä¸ªä¸»è¦çš„åŸå› æ˜¯ï¼Œone-hot è¯å‘é‡æ— æ³•å‡†ç¡®è¡¨è¾¾ä¸åŒè¯ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå¦‚æˆ‘ä»¬å¸¸å¸¸ä½¿ç”¨çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚\n",
    "\n",
    "Word2Vec è¯åµŒå…¥å·¥å…·çš„æå‡ºæ­£æ˜¯ä¸ºäº†è§£å†³ä¸Šé¢è¿™ä¸ªé—®é¢˜ï¼Œå®ƒå°†æ¯ä¸ªè¯è¡¨ç¤ºæˆä¸€ä¸ªå®šé•¿çš„å‘é‡ï¼Œå¹¶é€šè¿‡åœ¨è¯­æ–™åº“ä¸Šçš„é¢„è®­ç»ƒä½¿å¾—è¿™äº›å‘é‡èƒ½è¾ƒå¥½åœ°è¡¨è¾¾ä¸åŒè¯ä¹‹é—´çš„ç›¸ä¼¼å’Œç±»æ¯”å…³ç³»ï¼Œä»¥å¼•å…¥ä¸€å®šçš„è¯­ä¹‰ä¿¡æ¯ã€‚åŸºäºä¸¤ç§æ¦‚ç‡æ¨¡å‹çš„å‡è®¾ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸¤ç§ Word2Vec æ¨¡å‹ï¼š\n",
    "1. [Skip-Gram è·³å­—æ¨¡å‹](https://zh.d2l.ai/chapter_natural-language-processing/word2vec.html#%E8%B7%B3%E5%AD%97%E6%A8%A1%E5%9E%8B)ï¼šå‡è®¾èƒŒæ™¯è¯ç”±ä¸­å¿ƒè¯ç”Ÿæˆï¼Œå³å»ºæ¨¡ $P(w_o\\mid w_c)$ï¼Œå…¶ä¸­ $w_c$ ä¸ºä¸­å¿ƒè¯ï¼Œ$w_o$ ä¸ºä»»ä¸€èƒŒæ™¯è¯ï¼›\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mjsq84o9.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "2. [CBOW (continuous bag-of-words) è¿ç»­è¯è¢‹æ¨¡å‹](https://zh.d2l.ai/chapter_natural-language-processing/word2vec.html#%E8%BF%9E%E7%BB%AD%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B)ï¼šå‡è®¾ä¸­å¿ƒè¯ç”±èƒŒæ™¯è¯ç”Ÿæˆï¼Œå³å»ºæ¨¡ $P(w_c\\mid \\mathcal{W}_o)$ï¼Œå…¶ä¸­ $\\mathcal{W}_o$ ä¸ºèƒŒæ™¯è¯çš„é›†åˆã€‚\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mjt4r02n.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "åœ¨è¿™é‡Œæˆ‘ä»¬ä¸»è¦ä»‹ç» Skip-Gram æ¨¡å‹çš„å®ç°ï¼ŒCBOW å®ç°ä¸å…¶ç±»ä¼¼ï¼Œè¯»è€…å¯ä¹‹åè‡ªå·±å°è¯•å®ç°ã€‚åç»­çš„å†…å®¹å°†å¤§è‡´ä»ä»¥ä¸‹å››ä¸ªéƒ¨åˆ†å±•å¼€ï¼š\n",
    "\n",
    "1. PTB æ•°æ®é›†\n",
    "2. Skip-Gram è·³å­—æ¨¡å‹\n",
    "3. è´Ÿé‡‡æ ·è¿‘ä¼¼\n",
    "4. è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "graffitiCellId": "id_y7ocw2l",
    "id": "8627003642CB441780806CBC552BFAC1",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ube5b27",
    "id": "DD9999F086964C808616928EC7B736C0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## PTB æ•°æ®é›†\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼ŒWord2Vec èƒ½ä»è¯­æ–™ä¸­å­¦åˆ°å¦‚ä½•å°†ç¦»æ•£çš„è¯æ˜ å°„ä¸ºè¿ç»­ç©ºé—´ä¸­çš„å‘é‡ï¼Œå¹¶ä¿ç•™å…¶è¯­ä¹‰ä¸Šçš„ç›¸ä¼¼å…³ç³»ã€‚é‚£ä¹ˆä¸ºäº†è®­ç»ƒ Word2Vec æ¨¡å‹ï¼Œæˆ‘ä»¬å°±éœ€è¦ä¸€ä¸ªè‡ªç„¶è¯­è¨€è¯­æ–™åº“ï¼Œæ¨¡å‹å°†ä»ä¸­å­¦ä¹ å„ä¸ªå•è¯é—´çš„å…³ç³»ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç»å…¸çš„ PTB è¯­æ–™åº“è¿›è¡Œè®­ç»ƒã€‚[PTB (Penn Tree Bank)](https://catalog.ldc.upenn.edu/LDC99T42) æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„å°å‹è¯­æ–™åº“ï¼Œå®ƒé‡‡æ ·è‡ªã€Šåå°”è¡—æ—¥æŠ¥ã€‹çš„æ–‡ç« ï¼ŒåŒ…æ‹¬è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚æˆ‘ä»¬å°†åœ¨PTBè®­ç»ƒé›†ä¸Šè®­ç»ƒè¯åµŒå…¥æ¨¡å‹ã€‚\n",
    "\n",
    "### è½½å…¥æ•°æ®é›†\n",
    "\n",
    "æ•°æ®é›†è®­ç»ƒæ–‡ä»¶ `ptb.train.txt` ç¤ºä¾‹ï¼š\n",
    "```\n",
    "aer banknote berlitz calloway centrust cluett fromstein gitano guterman ...\n",
    "pierre  N years old will join the board as a nonexecutive director nov. N \n",
    "mr.  is chairman of  n.v. the dutch publishing group \n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "graffitiCellId": "id_9374ybr",
    "id": "FF5B1C79764A4EA8AA61C3DE984CBA0D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sentences: 42068\n",
      "# tokens: 24 ['aer', 'banknote', 'berlitz', 'calloway', 'centrust']\n",
      "# tokens: 15 ['pierre', '<unk>', 'N', 'years', 'old']\n",
      "# tokens: 11 ['mr.', '<unk>', 'is', 'chairman', 'of']\n"
     ]
    }
   ],
   "source": [
    "with open('../dataset/ptb_train1020/ptb.train.txt', 'r') as f:\n",
    "    lines = f.readlines() # è¯¥æ•°æ®é›†ä¸­å¥å­ä»¥æ¢è¡Œç¬¦ä¸ºåˆ†å‰²\n",
    "    raw_dataset = [st.split() for st in lines] # stæ˜¯sentenceçš„ç¼©å†™ï¼Œå•è¯ä»¥ç©ºæ ¼ä¸ºåˆ†å‰²\n",
    "print('# sentences: %d' % len(raw_dataset))\n",
    "\n",
    "# å¯¹äºæ•°æ®é›†çš„å‰3ä¸ªå¥å­ï¼Œæ‰“å°æ¯ä¸ªå¥å­çš„è¯æ•°å’Œå‰5ä¸ªè¯\n",
    "# å¥å°¾ç¬¦ä¸º '<eos>' ï¼Œç”Ÿåƒ»è¯å…¨ç”¨ '<unk>' è¡¨ç¤ºï¼Œæ•°å­—åˆ™è¢«æ›¿æ¢æˆäº† 'N'\n",
    "for st in raw_dataset[:3]:\n",
    "    print('# tokens:', len(st), st[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_whcovuv",
    "id": "4694FB2B910840BB8C65162A14881EB0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### å»ºç«‹è¯è¯­ç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filter(function, iterable)`ç”¨äºè¿‡æ»¤åºåˆ—ï¼Œè¿‡æ»¤æ‰ä¸ç¬¦åˆæ¡ä»¶çš„å…ƒç´ ï¼Œè¿”å›ä¸€ä¸ªè¿­ä»£å™¨å¯¹è±¡ï¼Œå¦‚æœè¦è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œå¯ä»¥ä½¿ç”¨ list() æ¥è½¬æ¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "graffitiCellId": "id_u6zhq97",
    "id": "70DD6E74F6854C289BA21B367D2397B4",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# tokens: 887100'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter([tk for st in raw_dataset for tk in st]) # tkæ˜¯tokençš„ç¼©å†™\n",
    "counter = dict(filter(lambda x: x[1] >= 5, counter.items())) # åªä¿ç•™åœ¨æ•°æ®é›†ä¸­è‡³å°‘å‡ºç°5æ¬¡çš„è¯\n",
    "\n",
    "idx_to_token = [tk for tk, _ in counter.items()]\n",
    "token_to_idx = {tk: idx for idx, tk in enumerate(idx_to_token)}\n",
    "dataset = [[token_to_idx[tk] for tk in st if tk in token_to_idx]\n",
    "           for st in raw_dataset] # raw_datasetä¸­çš„å•è¯åœ¨è¿™ä¸€æ­¥è¢«è½¬æ¢ä¸ºå¯¹åº”çš„idx\n",
    "num_tokens = sum([len(st) for st in dataset])\n",
    "'# tokens: %d' % num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9858"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_to_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_4zjy016",
    "id": "845942F28174462A87ADDBAE82957D15",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### äºŒæ¬¡é‡‡æ ·\n",
    "\n",
    "æ–‡æœ¬æ•°æ®ä¸­ä¸€èˆ¬ä¼šå‡ºç°ä¸€äº›é«˜é¢‘è¯ï¼Œå¦‚è‹±æ–‡ä¸­çš„â€œtheâ€â€œaâ€å’Œâ€œinâ€ã€‚é€šå¸¸æ¥è¯´ï¼Œåœ¨ä¸€ä¸ªèƒŒæ™¯çª—å£ä¸­ï¼Œä¸€ä¸ªè¯ï¼ˆå¦‚â€œchipâ€ï¼‰å’Œè¾ƒä½é¢‘è¯ï¼ˆå¦‚â€œmicroprocessorâ€ï¼‰åŒæ—¶å‡ºç°æ¯”å’Œè¾ƒé«˜é¢‘è¯ï¼ˆå¦‚â€œtheâ€ï¼‰åŒæ—¶å‡ºç°å¯¹è®­ç»ƒè¯åµŒå…¥æ¨¡å‹æ›´æœ‰ç›Šã€‚å› æ­¤ï¼Œè®­ç»ƒè¯åµŒå…¥æ¨¡å‹æ—¶å¯ä»¥å¯¹è¯è¿›è¡ŒäºŒæ¬¡é‡‡æ ·ã€‚ å…·ä½“æ¥è¯´ï¼Œæ•°æ®é›†ä¸­æ¯ä¸ªè¢«ç´¢å¼•è¯ $w_i$ å°†æœ‰ä¸€å®šæ¦‚ç‡è¢«ä¸¢å¼ƒï¼Œè¯¥ä¸¢å¼ƒæ¦‚ç‡ä¸º\n",
    "\n",
    "\n",
    "$$\n",
    "P(w_i)=\\max(1-\\sqrt{\\frac{t}{f(w_i)}},0)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­  $f(w_i)$  æ˜¯æ•°æ®é›†ä¸­è¯ $w_i$ çš„ä¸ªæ•°ä¸æ€»è¯æ•°ä¹‹æ¯”ï¼Œå¸¸æ•° $t$ æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼ˆå®éªŒä¸­è®¾ä¸º $10^{âˆ’4}$ï¼‰ã€‚å¯è§ï¼Œåªæœ‰å½“ $f(w_i)>t$ æ—¶ï¼Œæˆ‘ä»¬æ‰æœ‰å¯èƒ½åœ¨äºŒæ¬¡é‡‡æ ·ä¸­ä¸¢å¼ƒè¯ $w_i$ï¼Œå¹¶ä¸”è¶Šé«˜é¢‘çš„è¯è¢«ä¸¢å¼ƒçš„æ¦‚ç‡è¶Šå¤§ã€‚å…·ä½“çš„ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "graffitiCellId": "id_yg9kj6g",
    "id": "4B82B59FCC244E11AA7335909F6B588A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens: 376095\n",
      "# the: before=50770, after=2214\n",
      "# join: before=45, after=45\n"
     ]
    }
   ],
   "source": [
    "def discard(idx):\n",
    "    '''\n",
    "    @params:\n",
    "        idx: å•è¯çš„ä¸‹æ ‡\n",
    "    @return: True/False è¡¨ç¤ºæ˜¯å¦ä¸¢å¼ƒè¯¥å•è¯\n",
    "    '''\n",
    "    return random.uniform(0, 1) < 1 - math.sqrt(1e-4 / (counter[idx_to_token[idx]] / num_tokens))\n",
    "\n",
    "subsampled_dataset = [[tk for tk in st if not discard(tk)] for st in dataset]\n",
    "print('# tokens: %d' % sum([len(st) for st in subsampled_dataset]))\n",
    "\n",
    "def compare_counts(token):\n",
    "    return '# %s: before=%d, after=%d' % (token, \n",
    "                                          sum([st.count(token_to_idx[token]) for st in dataset]), \n",
    "                                          sum([st.count(token_to_idx[token]) for st in subsampled_dataset]))\n",
    "\n",
    "print(compare_counts('the'))\n",
    "print(compare_counts('join'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_u88x2eb",
    "id": "18BE417013E049A3B5A3EC7B607EE554",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### æå–ä¸­å¿ƒè¯å’ŒèƒŒæ™¯è¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zip([iterable, ...])`å‡½æ•°ç”¨äºå°†å¯è¿­ä»£çš„å¯¹è±¡ä½œä¸ºå‚æ•°ï¼Œå°†å¯¹è±¡ä¸­å¯¹åº”çš„å…ƒç´ æ‰“åŒ…æˆä¸€ä¸ªä¸ªå…ƒç»„ï¼Œç„¶åè¿”å›ç”±è¿™äº›å…ƒç»„ç»„æˆçš„åˆ—è¡¨ã€‚å¦‚æœå„ä¸ªè¿­ä»£å™¨çš„å…ƒç´ ä¸ªæ•°ä¸ä¸€è‡´ï¼Œåˆ™è¿”å›åˆ—è¡¨é•¿åº¦ä¸æœ€çŸ­çš„å¯¹è±¡ç›¸åŒï¼Œåˆ©ç”¨ * å·æ“ä½œç¬¦ï¼Œå¯ä»¥å°†å…ƒç»„è§£å‹ä¸ºåˆ—è¡¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "graffitiCellId": "id_a0ayzaz",
    "id": "56C4719FE9A64B468F9B0081DD25ABBC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
      "center 0 has contexts [1, 2]\n",
      "center 1 has contexts [0, 2, 3]\n",
      "center 2 has contexts [1, 3]\n",
      "center 3 has contexts [1, 2, 4, 5]\n",
      "center 4 has contexts [3, 5]\n",
      "center 5 has contexts [3, 4, 6]\n",
      "center 6 has contexts [4, 5]\n",
      "center 7 has contexts [8, 9]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [7, 8]\n",
      "center 1 has contexts [2]\n",
      "center 2 has contexts [1, 3, 4]\n",
      "center 3 has contexts [1, 2, 4, 5]\n",
      "center 4 has contexts [3, 5]\n",
      "center 5 has contexts [4, 6]\n",
      "center 6 has contexts [5, 7]\n",
      "center 7 has contexts [6, 8]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [8]\n"
     ]
    }
   ],
   "source": [
    "def get_centers_and_contexts(dataset, max_window_size):\n",
    "    '''\n",
    "    @params:\n",
    "        dataset: åŒ…å«æ‰€æœ‰å¥å­çš„listï¼Œæ¯ä¸ªå¥å­åˆ™ä¸ºå•è¯çš„listï¼Œæ­¤æ—¶å•è¯å·²ç»è¢«è½¬æ¢ä¸ºç›¸åº”æ•°å­—ä¸‹æ ‡\n",
    "        max_window_size: èƒŒæ™¯è¯çš„è¯çª—å¤§å°çš„æœ€å¤§å€¼ï¼Œè¯çª—å¤§å°æŒ‡çš„æ˜¯å•ä¾§çš„ï¼Œå¦‚è¯çª—å¤§å°ä¸º3ï¼Œåˆ™èƒŒæ™¯è¯ä¸º6ä¸ª\n",
    "    @return:\n",
    "        centers: ä¸­å¿ƒè¯çš„é›†åˆ\n",
    "        contexts: äºŒé‡åˆ—è¡¨ï¼ŒèƒŒæ™¯è¯çª—çš„é›†åˆï¼Œä¸ä¸­å¿ƒè¯å¯¹åº”ï¼Œæ¯ä¸ªèƒŒæ™¯è¯çª—åˆ™ä¸ºèƒŒæ™¯è¯çš„é›†åˆ\n",
    "    '''\n",
    "    centers, contexts = [], []\n",
    "    for st in dataset:\n",
    "        if len(st) < 2:  # æ¯ä¸ªå¥å­è‡³å°‘è¦æœ‰2ä¸ªè¯æ‰å¯èƒ½ç»„æˆä¸€å¯¹â€œä¸­å¿ƒè¯-èƒŒæ™¯è¯â€\n",
    "            continue\n",
    "        centers += st\n",
    "        for center_i in range(len(st)):\n",
    "            window_size = random.randint(1, max_window_size) # éšæœºé€‰å–èƒŒæ™¯è¯çª—å¤§å°\n",
    "            indices = list(range(max(0, center_i - window_size), min(len(st), center_i + 1 + window_size)))\n",
    "            indices.remove(center_i)  # å°†ä¸­å¿ƒè¯æ’é™¤åœ¨èƒŒæ™¯è¯ä¹‹å¤–\n",
    "            contexts.append([st[idx] for idx in indices])\n",
    "    return centers, contexts\n",
    "\n",
    "all_centers, all_contexts = get_centers_and_contexts(subsampled_dataset, 5)\n",
    "\n",
    "tiny_dataset = [list(range(7)), list(range(7, 10)), list(range(1, 10))]\n",
    "print('dataset', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('center', center, 'has contexts', context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_161ief2",
    "id": "3853063E40E14F7DA7DCA410A0A3C617",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "*æ³¨ï¼šæ•°æ®æ‰¹é‡è¯»å–çš„å®ç°éœ€è¦ä¾èµ–è´Ÿé‡‡æ ·è¿‘ä¼¼çš„å®ç°ï¼Œæ•…æ”¾äºè´Ÿé‡‡æ ·è¿‘ä¼¼éƒ¨åˆ†è¿›è¡Œè®²è§£ã€‚*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_s7nai85",
    "id": "E0C8301D7DB340CDABD81A23520A340D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Skip-Gram è·³å­—æ¨¡å‹\n",
    "\n",
    "åœ¨è·³å­—æ¨¡å‹ä¸­ï¼Œæ¯ä¸ªè¯è¢«è¡¨ç¤ºæˆä¸¤ä¸ª $d$ ç»´å‘é‡ï¼Œç”¨æ¥è®¡ç®—æ¡ä»¶æ¦‚ç‡ã€‚å‡è®¾è¿™ä¸ªè¯åœ¨è¯å…¸ä¸­ç´¢å¼•ä¸º $i$ ï¼Œå½“å®ƒä¸ºä¸­å¿ƒè¯æ—¶å‘é‡è¡¨ç¤ºä¸º $\\boldsymbol{v}_i\\in\\mathbb{R}^d$ï¼Œè€Œä¸ºèƒŒæ™¯è¯æ—¶å‘é‡è¡¨ç¤ºä¸º $\\boldsymbol{u}_i\\in\\mathbb{R}^d$ ã€‚è®¾ä¸­å¿ƒè¯ $w_c$ åœ¨è¯å…¸ä¸­ç´¢å¼•ä¸º $c$ï¼ŒèƒŒæ™¯è¯ $w_o$ åœ¨è¯å…¸ä¸­ç´¢å¼•ä¸º $o$ï¼Œæˆ‘ä»¬å‡è®¾ç»™å®šä¸­å¿ƒè¯ç”ŸæˆèƒŒæ™¯è¯çš„æ¡ä»¶æ¦‚ç‡æ»¡è¶³ä¸‹å¼ï¼š\n",
    "\n",
    "\n",
    "$$\n",
    "P(w_o\\mid w_c)=\\frac{\\exp(\\boldsymbol{u}_o^\\top \\boldsymbol{v}_c)}{\\sum_{i\\in\\mathcal{V}}\\exp(\\boldsymbol{u}_i^\\top \\boldsymbol{v}_c)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_j38gtz0",
    "id": "C7B5BB9D5FD54489BF6E3F42E31B835F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### PyTorch é¢„ç½®çš„ Embedding å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "graffitiCellId": "id_7he6kmh",
    "id": "68DF20EE03824200887D18AA3363E7F9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5190,  1.4930,  0.1982, -0.8273],\n",
      "        [-0.9070, -0.2818,  0.5593,  0.1629],\n",
      "        [ 2.2151,  0.9457,  0.1835,  0.0972],\n",
      "        [ 1.6417,  0.1047,  1.8127, -0.4496],\n",
      "        [ 0.4965, -0.7347,  0.1808,  0.8918],\n",
      "        [-1.8812,  0.1699, -0.0854, -0.2730],\n",
      "        [-0.5225,  0.9700, -0.9730,  1.3435],\n",
      "        [-0.6116,  0.8471,  1.8029,  0.7194],\n",
      "        [ 0.6153,  1.3005,  0.1029, -1.5952],\n",
      "        [-0.0667,  0.1833,  2.0840,  1.4245]], requires_grad=True)\n",
      "tensor([[[-0.9070, -0.2818,  0.5593,  0.1629],\n",
      "         [ 2.2151,  0.9457,  0.1835,  0.0972],\n",
      "         [ 1.6417,  0.1047,  1.8127, -0.4496]],\n",
      "\n",
      "        [[ 0.4965, -0.7347,  0.1808,  0.8918],\n",
      "         [-1.8812,  0.1699, -0.0854, -0.2730],\n",
      "         [-0.5225,  0.9700, -0.9730,  1.3435]]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=10, embedding_dim=4)\n",
    "print(embed.weight)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.long) #(2,3)ğŸ‘‰(2,3,4)\n",
    "print(embed(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_hevvqgv",
    "id": "8421DAEC55314EBE80D2EC59EAB73099",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### PyTorch é¢„ç½®çš„æ‰¹é‡ä¹˜æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "graffitiCellId": "id_8i4omp4",
    "id": "12B88D54095F48F58397626D8F1935E3",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "X = torch.ones((2, 1, 4))\n",
    "Y = torch.ones((2, 4, 6))\n",
    "print(torch.bmm(X, Y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ol1tdyu",
    "id": "80F8440D701D4F3CBD4C4FFD3608E697",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Skip-Gram æ¨¡å‹çš„å‰å‘è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "graffitiCellId": "id_x6q9jp9",
    "id": "AAA4F7E268764809836AAADD7FD2A8AE",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    '''\n",
    "    @params:\n",
    "        center: ä¸€äº›ä¸­å¿ƒè¯çš„ä¸‹æ ‡ï¼Œå½¢çŠ¶ä¸º (n, 1) çš„æ•´æ•°å¼ é‡\n",
    "        contexts_and_negatives: èƒŒæ™¯è¯å’Œå™ªéŸ³è¯ä¸‹æ ‡ï¼Œå½¢çŠ¶ä¸º (n, m) çš„æ•´æ•°å¼ é‡\n",
    "        embed_v: ä¸­å¿ƒè¯çš„ embedding å±‚\n",
    "        embed_u: èƒŒæ™¯è¯çš„ embedding å±‚\n",
    "    @return:\n",
    "        pred: ä¸­å¿ƒè¯ä¸èƒŒæ™¯è¯ï¼ˆæˆ–å™ªéŸ³è¯ï¼‰çš„å†…ç§¯ï¼Œä¹‹åå¯ç”¨äºè®¡ç®—æ¦‚ç‡ p(w_o|w_c)\n",
    "    '''\n",
    "    v = embed_v(center) # shape of (n, 1, d)\n",
    "    u = embed_u(contexts_and_negatives) # shape of (n, m, d)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1)) # bmm((n, 1, d), (n, d, m)) => shape of (n, 1, m)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_rb8yuyq",
    "id": "8FE236CF785F474F9BBB4BB3D88AA4CC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## è´Ÿé‡‡æ ·è¿‘ä¼¼\n",
    "\n",
    "ç”±äº softmax è¿ç®—è€ƒè™‘äº†èƒŒæ™¯è¯å¯èƒ½æ˜¯è¯å…¸ $\\mathcal{V}$ ä¸­çš„ä»»ä¸€è¯ï¼Œå¯¹äºå«å‡ åä¸‡æˆ–ä¸Šç™¾ä¸‡è¯çš„è¾ƒå¤§è¯å…¸ï¼Œå°±å¯èƒ½å¯¼è‡´è®¡ç®—çš„å¼€é”€è¿‡å¤§ã€‚æˆ‘ä»¬å°†ä»¥ skip-gram æ¨¡å‹ä¸ºä¾‹ï¼Œä»‹ç»è´Ÿé‡‡æ · (negative sampling) çš„å®ç°æ¥å°è¯•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\n",
    "\n",
    "è´Ÿé‡‡æ ·æ–¹æ³•ç”¨ä»¥ä¸‹å…¬å¼æ¥è¿‘ä¼¼æ¡ä»¶æ¦‚ç‡ $P(w_o\\mid w_c)=\\frac{\\exp(\\boldsymbol{u}_o^\\top \\boldsymbol{v}_c)}{\\sum_{i\\in\\mathcal{V}}\\exp(\\boldsymbol{u}_i^\\top \\boldsymbol{v}_c)}$ï¼š\n",
    "\n",
    "\n",
    "$$\n",
    "P(w_o\\mid w_c)=P(D=1\\mid w_c,w_o)\\prod_{k=1,w_k\\sim P(w)}^K P(D=0\\mid w_c,w_k)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ $P(D=1\\mid w_c,w_o)=\\sigma(\\boldsymbol{u}_o^\\top\\boldsymbol{v}_c)$ï¼Œ$\\sigma(\\cdot)$ ä¸º sigmoid å‡½æ•°ã€‚å¯¹äºä¸€å¯¹ä¸­å¿ƒè¯å’ŒèƒŒæ™¯è¯ï¼Œæˆ‘ä»¬ä»è¯å…¸ä¸­éšæœºé‡‡æ · $K$ ä¸ªå™ªå£°è¯ï¼ˆå®éªŒä¸­è®¾ $K=5$ï¼‰ã€‚æ ¹æ® Word2Vec è®ºæ–‡çš„å»ºè®®ï¼Œå™ªå£°è¯é‡‡æ ·æ¦‚ç‡ $P(w)$ è®¾ä¸º $w$ è¯é¢‘ä¸æ€»è¯é¢‘ä¹‹æ¯”çš„ $0.75$ æ¬¡æ–¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "graffitiCellId": "id_st81puo",
    "id": "C6A1BDB699EB49AA8EEB49C295EACBF7",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_negatives(all_contexts, sampling_weights, K):\n",
    "    '''\n",
    "    @params:\n",
    "        all_contexts: [[w_o1, w_o2, ...w_om], [...], ... ]æ¯ä¸ªä¸­å¿ƒè¯çš„èƒŒæ™¯è¯è¯çª—\n",
    "        sampling_weights: æ¯ä¸ªå•è¯çš„å™ªå£°è¯é‡‡æ ·æ¦‚ç‡\n",
    "        K: éšæœºé‡‡æ ·ä¸ªæ•°\n",
    "    @return:\n",
    "        all_negatives: [[w_o11, w_o12, ...,w_o1K, w_o21, w_o22, ...,w_o2K, ..., w_omK], [...], ...]\n",
    "        æ¯ä¸€å¯¹ä¸­å¿ƒè¯å’ŒèƒŒæ™¯è¯ï¼Œé‡‡æ ·Kä¸ªå™ªå£°è¯\n",
    "    '''\n",
    "    all_negatives, neg_candidates, i = [], [], 0\n",
    "    population = list(range(len(sampling_weights)))\n",
    "    for contexts in all_contexts:  #å¾ªç¯æ¯ä¸ªèƒŒæ™¯è¯çª—\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            if i == len(neg_candidates):\n",
    "                # æ ¹æ®æ¯ä¸ªè¯çš„æƒé‡ï¼ˆsampling_weightsï¼‰éšæœºç”Ÿæˆkä¸ªè¯çš„ç´¢å¼•ä½œä¸ºå™ªå£°è¯ã€‚\n",
    "                # ä¸ºäº†é«˜æ•ˆè®¡ç®—ï¼Œå¯ä»¥å°†kè®¾å¾—ç¨å¤§ä¸€ç‚¹\n",
    "                i, neg_candidates = 0, random.choices(population, sampling_weights, k=int(1e5))\n",
    "            neg, i = neg_candidates[i], i + 1\n",
    "            # å™ªå£°è¯ä¸èƒ½æ˜¯èƒŒæ™¯è¯\n",
    "            if neg not in set(contexts):\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "sampling_weights = [counter[w]**0.75 for w in idx_to_token] #è¯å…¸ä¸­çš„æ¯ä¸€ä¸ªè¯éƒ½æœ‰ä¸€ä¸ªæƒé‡\n",
    "all_negatives = get_negatives(all_contexts, sampling_weights, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸­å¿ƒè¯æ•°é‡ï¼š375126\n",
      "è¯çª—æ•°é‡ï¼š375126ï¼Œç¬¬ä¸€ä¸ªä¸­å¿ƒè¯è¯çª—å¤§å°ï¼š3\n",
      "å™ªå£°è¯é‡‡æ ·çš„æ•°é‡(åº”=è¯çª—æ•°)ï¼š375126ï¼Œç¬¬1ä¸ªä¸­å¿ƒè¯-èƒŒæ™¯è¯çš„å™ªå£°è¯é‡‡æ ·æ•°é‡ï¼š15\n"
     ]
    }
   ],
   "source": [
    "print(\"ä¸­å¿ƒè¯æ•°é‡ï¼š{}\".format(len(all_centers)))\n",
    "print(\"è¯çª—æ•°é‡ï¼š{}ï¼Œç¬¬ä¸€ä¸ªä¸­å¿ƒè¯è¯çª—å¤§å°ï¼š{}\".format(len(all_contexts), len(all_contexts[0])))\n",
    "print(\"å™ªå£°è¯é‡‡æ ·çš„æ•°é‡(åº”=è¯çª—æ•°)ï¼š{}ï¼Œç¬¬1ä¸ªä¸­å¿ƒè¯-èƒŒæ™¯è¯çš„å™ªå£°è¯é‡‡æ ·æ•°é‡ï¼š{}\".format(len(all_negatives), len(all_negatives[0])))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random.choices(population, weights=None, *, cum_weights=None, k=1)`ï¼šä»populationä¸­è¿›è¡ŒKæ¬¡éšæœºé€‰å–ï¼Œæ¯æ¬¡é€‰å–ä¸€ä¸ªå…ƒç´ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_g7431va",
    "id": "43F68EDDF24849BE8791D07F0618F9DD",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "*æ³¨ï¼šé™¤è´Ÿé‡‡æ ·æ–¹æ³•å¤–ï¼Œè¿˜æœ‰å±‚åº softmax (hiererarchical softmax) æ–¹æ³•ä¹Ÿå¯ä»¥ç”¨æ¥è§£å†³è®¡ç®—é‡è¿‡å¤§çš„é—®é¢˜ï¼Œè¯·å‚è€ƒ[åŸä¹¦10.2.2èŠ‚](https://zh.d2l.ai/chapter_natural-language-processing/approx-training.html#%E5%B1%82%E5%BA%8Fsoftmax)ã€‚*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_jhrav4e",
    "id": "F991A9C6E28C42848DD393E4F891D49D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### æ‰¹é‡è¯»å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "graffitiCellId": "id_shkut5w",
    "id": "FF3BDA1024C94EB3A760EBA5FD583B4A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape: torch.Size([512, 1])\n",
      "contexts_negatives shape: torch.Size([512, 60])\n",
      "masks shape: torch.Size([512, 60])\n",
      "labels shape: torch.Size([512, 60])\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, centers, contexts, negatives):\n",
    "        assert len(centers) == len(contexts) == len(negatives)  # æ¯ä¸ªä¸­å¿ƒè¯å¯¹åº”1ä¸ªèƒŒæ™¯è¯çª—ï¼Œå¯¹åº”1ä¸ªè´Ÿé‡‡æ ·è¯çª—ï¼Œæ¯ä¸ªèƒŒæ™¯è¯æœ‰Kä¸ªå™ªå£°è¯\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.centers[index], self.contexts[index], self.negatives[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.centers)\n",
    "    \n",
    "def batchify(data):\n",
    "    '''\n",
    "    ç”¨ä½œDataLoaderçš„å‚æ•°collate_fn\n",
    "    @params:\n",
    "        data: é•¿ä¸ºbatch_sizeçš„åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯__getitem__å¾—åˆ°çš„ç»“æœ\n",
    "    @outputs:\n",
    "        batch: æ‰¹é‡åŒ–åå¾—åˆ° (centers, contexts_negatives, masks, labels) å…ƒç»„\n",
    "        centers: ä¸­å¿ƒè¯ä¸‹æ ‡ï¼Œå½¢çŠ¶ä¸º (n, 1) çš„æ•´æ•°å¼ é‡\n",
    "        contexts_negatives: èƒŒæ™¯è¯å’Œå™ªå£°è¯çš„ä¸‹æ ‡ï¼Œå½¢çŠ¶ä¸º (n, m) çš„æ•´æ•°å¼ é‡\n",
    "        masks: ä¸è¡¥é½ç›¸å¯¹åº”çš„æ©ç ï¼Œå½¢çŠ¶ä¸º (n, m) çš„0/1æ•´æ•°å¼ é‡\n",
    "        labels: æŒ‡ç¤ºèƒŒæ™¯è¯çš„æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º (n, m) çš„0/1æ•´æ•°å¼ é‡\n",
    "    '''\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)] # ä½¿ç”¨æ©ç å˜é‡maskæ¥é¿å…å¡«å……é¡¹å¯¹æŸå¤±å‡½æ•°è®¡ç®—çš„å½±å“\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "        batch = (torch.tensor(centers).view(-1, 1), torch.tensor(contexts_negatives), torch.tensor(masks), torch.tensor(labels))\n",
    "    return batch\n",
    "\n",
    "batch_size = 512\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "dataset = MyDataset(all_centers, all_contexts, all_negatives)\n",
    "data_iter = Data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                            collate_fn=batchify,   # collate_fnï¼šå¦‚ä½•å–æ ·æœ¬çš„ï¼Œå¯ä»¥å®šä¹‰è‡ªå·±çš„å‡½æ•°æ¥å‡†ç¡®åœ°å®ç°æƒ³è¦çš„åŠŸèƒ½\n",
    "                            num_workers=num_workers)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(['centers', 'contexts_negatives', 'masks',\n",
    "                           'labels'], batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_hf5q360",
    "id": "3AC214600B9F4A73B87CD4B57384BB3B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## è®­ç»ƒæ¨¡å‹\n",
    "\n",
    "### æŸå¤±å‡½æ•°\n",
    "\n",
    "åº”ç”¨è´Ÿé‡‡æ ·æ–¹æ³•åï¼Œæˆ‘ä»¬å¯åˆ©ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„å¯¹æ•°ç­‰ä»·å½¢å¼å°†æŸå¤±å‡½æ•°å®šä¹‰ä¸ºå¦‚ä¸‹\n",
    "\n",
    "\n",
    "$$\n",
    "\\sum_{t=1}^T\\sum_{-m\\le j\\le m,j\\ne 0} [-\\log P(D=1\\mid w^{(t)},w^{(t+j)})-\\sum_{k=1,w_k\\sim P(w)^K}\\log P(D=0\\mid w^{(t)},w_k)]\n",
    "$$\n",
    "\n",
    "\n",
    "æ ¹æ®è¿™ä¸ªæŸå¤±å‡½æ•°çš„å®šä¹‰ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œè®¡ç®—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "graffitiCellId": "id_ap2woj6",
    "id": "6BDDED9801FF43B98CD51ED86B12D450",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8740, 1.2100])\n",
      "0.8740\n",
      "1.2100\n"
     ]
    }
   ],
   "source": [
    "class SigmoidBinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SigmoidBinaryCrossEntropyLoss, self).__init__()\n",
    "    def forward(self, inputs, targets, mask=None):\n",
    "        '''\n",
    "        @params:\n",
    "            inputs: ç»è¿‡sigmoidå±‚åä¸ºé¢„æµ‹D=1çš„æ¦‚ç‡\n",
    "            targets: 0/1å‘é‡ï¼Œ1ä»£è¡¨èƒŒæ™¯è¯ï¼Œ0ä»£è¡¨å™ªéŸ³è¯\n",
    "        @return:\n",
    "            res: å¹³å‡åˆ°æ¯ä¸ªlabelçš„loss\n",
    "        '''\n",
    "        inputs, targets, mask = inputs.float(), targets.float(), mask.float()\n",
    "        res = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\", weight=mask)\n",
    "        res = res.sum(dim=1) / mask.float().sum(dim=1)\n",
    "        return res\n",
    "\n",
    "loss = SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "pred = torch.tensor([[1.5, 0.3, -1, 2], [1.1, -0.6, 2.2, 0.4]])\n",
    "label = torch.tensor([[1, 0, 0, 0], [1, 1, 0, 0]]) # æ ‡ç­¾å˜é‡labelä¸­çš„1å’Œ0åˆ†åˆ«ä»£è¡¨èƒŒæ™¯è¯å’Œå™ªå£°è¯\n",
    "mask = torch.tensor([[1, 1, 1, 1], [1, 1, 1, 0]])  # æ©ç å˜é‡\n",
    "print(loss(pred, label, mask))\n",
    "\n",
    "def sigmd(x):\n",
    "    return - math.log(1 / (1 + math.exp(-x)))\n",
    "print('%.4f' % ((sigmd(1.5) + sigmd(-0.3) + sigmd(1) + sigmd(-2)) / 4)) # æ³¨æ„1-sigmoid(x) = sigmoid(-x)\n",
    "print('%.4f' % ((sigmd(1.1) + sigmd(-0.6) + sigmd(-2.2)) / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_zz57d6p",
    "id": "3F1EB2F8E34D45088D8A8872FAE1C726",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### æ¨¡å‹åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "graffitiCellId": "id_k9ax2h6",
    "id": "EE565E07272B40C691196EED5695BC5D",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "net = nn.Sequential(nn.Embedding(num_embeddings=len(idx_to_token), embedding_dim=embed_size),\n",
    "                    nn.Embedding(num_embeddings=len(idx_to_token), embedding_dim=embed_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_9ahavii",
    "id": "F178519AEE504029B3603E4D006BA839",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "graffitiCellId": "id_9fx6rj4",
    "id": "2DA9D996EE3E44B49DE0D2FAC370E1DD",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on cuda\n",
      "epoch 1, loss 1.97, time 651.40s\n",
      "epoch 2, loss 0.62, time 639.98s\n",
      "epoch 3, loss 0.45, time 642.68s\n",
      "epoch 4, loss 0.39, time 639.91s\n",
      "epoch 5, loss 0.37, time 640.19s\n"
     ]
    }
   ],
   "source": [
    "def train(net, lr, num_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = torch.device('cpu')\n",
    "    print(\"train on\", device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        start, l_sum, n = time.time(), 0.0, 0\n",
    "        for batch in data_iter:\n",
    "            center, context_negative, mask, label = [d.to(device) for d in batch]\n",
    "            # center: (batch_size, 1), context_negative, mask, label: (batch_size, max_len)\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            # pred: (batch_size, 1, max_len)\n",
    "            l = loss(pred.view(label.shape), label, mask).mean() # ä¸€ä¸ªbatchçš„å¹³å‡loss\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum += l.cpu().item()\n",
    "            n += 1\n",
    "        print('epoch %d, loss %.2f, time %.2fs'\n",
    "              % (epoch + 1, l_sum / n, time.time() - start))\n",
    "\n",
    "train(net, 0.01, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_yb3aapa",
    "id": "855E5C6515884CD596D3B1C1E0CC1978",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "train on cpu\n",
    "epoch 1, loss 0.61, time 221.30s\n",
    "epoch 2, loss 0.42, time 227.70s\n",
    "epoch 3, loss 0.38, time 240.50s\n",
    "epoch 4, loss 0.36, time 253.79s\n",
    "epoch 5, loss 0.34, time 238.51s\n",
    "```\n",
    "\n",
    "*æ³¨ï¼šç”±äºæœ¬åœ°CPUä¸Šè®­ç»ƒæ—¶é—´è¿‡é•¿ï¼Œæ•…åªæˆªå–äº†è¿è¡Œçš„ç»“æœï¼ŒååŒã€‚å¤§å®¶å¯ä»¥è‡ªè¡Œåœ¨ç½‘ç«™ä¸Šè®­ç»ƒã€‚*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_bw1dtd1",
    "id": "A5DAB2B7CC6A41668D2F5A0061C54728",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### æµ‹è¯•æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "graffitiCellId": "id_wm2rrhl",
    "id": "838B4878856C457889DAA35A29948029",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.600: systems\n",
      "cosine sim=0.563: software\n",
      "cosine sim=0.546: maker\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    '''\n",
    "    @params:\n",
    "        query_token: ç»™å®šçš„è¯è¯­\n",
    "        k: è¿‘ä¹‰è¯çš„ä¸ªæ•°\n",
    "        embed: é¢„è®­ç»ƒè¯å‘é‡\n",
    "    '''\n",
    "    W = embed.weight.data\n",
    "    x = W[token_to_idx[query_token]]\n",
    "    # æ·»åŠ çš„1e-9æ˜¯ä¸ºäº†æ•°å€¼ç¨³å®šæ€§\n",
    "    cos = torch.matmul(W, x) / (torch.sum(W * W, dim=1) * torch.sum(x * x) + 1e-9).sqrt()\n",
    "    _, topk = torch.topk(cos, k=k+1)\n",
    "    topk = topk.cpu().numpy()\n",
    "    for i in topk[1:]:  # é™¤å»è¾“å…¥è¯\n",
    "        print('cosine sim=%.3f: %s' % (cos[i], (idx_to_token[i])))\n",
    "        \n",
    "get_similar_tokens('computer', 3, net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_htzr4u1",
    "id": "3E45FF89FD794158AAD153F605942091",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "cosine sim=0.446: intel\n",
    "cosine sim=0.427: computer\n",
    "cosine sim=0.427: computers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_g9tjvnn",
    "id": "17C8660147A846FEB9389CEF51AEC536",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## å‚è€ƒ\n",
    "* [Dive into Deep Learning](https://d2l.ai/chapter_natural-language-processing/word2vec.html). Ch14.1-14.4.\n",
    "* [åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ](http://zh.gluon.ai/chapter_natural-language-processing/word2vec.html). Ch10.1-10.3.\n",
    "* [Dive-into-DL-PyTorch on GitHub](https://github.com/ShusenTang/Dive-into-DL-PyTorch/blob/master/code/chapter10_natural-language-processing/10.3_word2vec-pytorch.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch1-gpu]",
   "language": "python",
   "name": "conda-env-pytorch1-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
