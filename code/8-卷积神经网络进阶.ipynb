{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3700F0383ACD456594322246327904AB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " # æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E59CD3957F874D2D9FB1B0D7C1A3566C",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "LeNet:  åœ¨å¤§çš„çœŸå®æ•°æ®é›†ä¸Šçš„è¡¨ç°å¹¶ä¸å°½å¦‚â¼ˆæ„ã€‚     \n",
    "1.ç¥ç»ç½‘ç»œè®¡ç®—å¤æ‚ã€‚  \n",
    "2.è¿˜æ²¡æœ‰â¼¤é‡æ·±â¼Šç ”ç©¶å‚æ•°åˆå§‹åŒ–å’Œâ¾®å‡¸ä¼˜åŒ–ç®—æ³•ç­‰è¯¸å¤šé¢†åŸŸã€‚  \n",
    "  \n",
    "æœºå™¨å­¦ä¹ çš„ç‰¹å¾æå–:æ‰‹å·¥å®šä¹‰çš„ç‰¹å¾æå–å‡½æ•°  \n",
    "ç¥ç»ç½‘ç»œçš„ç‰¹å¾æå–ï¼šé€šè¿‡å­¦ä¹ å¾—åˆ°æ•°æ®çš„å¤šçº§è¡¨å¾ï¼Œå¹¶é€çº§è¡¨â½°è¶Šæ¥è¶ŠæŠ½è±¡çš„æ¦‚å¿µæˆ–æ¨¡å¼ã€‚  \n",
    "  \n",
    "ç¥ç»ç½‘ç»œå‘å±•çš„é™åˆ¶:æ•°æ®ã€ç¡¬ä»¶"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "894A96EBC1404E008C042A83D1A053F9",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### AlexNet\n",
    "é¦–æ¬¡è¯æ˜äº†å­¦ä¹ åˆ°çš„ç‰¹å¾å¯ä»¥è¶…è¶Šâ¼¿â¼¯è®¾è®¡çš„ç‰¹å¾ï¼Œä»è€Œâ¼€ä¸¾æ‰“ç ´è®¡ç®—æœºè§†è§‰ç ”ç©¶çš„å‰çŠ¶ã€‚   \n",
    "**ç‰¹å¾ï¼š**\n",
    "1. 8å±‚å˜æ¢ï¼Œå…¶ä¸­æœ‰5å±‚å·ç§¯å’Œ2å±‚å…¨è¿æ¥éšè—å±‚ï¼Œä»¥åŠ1ä¸ªå…¨è¿æ¥è¾“å‡ºå±‚ã€‚\n",
    "2. å°†sigmoidæ¿€æ´»å‡½æ•°æ”¹æˆäº†æ›´åŠ ç®€å•çš„ReLUæ¿€æ´»å‡½æ•°ã€‚\n",
    "3. ç”¨Dropoutæ¥æ§åˆ¶å…¨è¿æ¥å±‚çš„æ¨¡å‹å¤æ‚åº¦ã€‚\n",
    "4. å¼•å…¥æ•°æ®å¢å¼ºï¼Œå¦‚ç¿»è½¬ã€è£å‰ªå’Œé¢œè‰²å˜åŒ–ï¼Œä»è€Œè¿›ä¸€æ­¥æ‰©å¤§æ•°æ®é›†æ¥ç¼“è§£è¿‡æ‹Ÿåˆã€‚\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5kv4gpx88.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"package\") \n",
    "import d2lzh_pytorch as d2l\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DD41B540CFAB491B9D43105C3D90647C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # è¿ç»­3ä¸ªå·ç§¯å±‚ï¼Œä¸”ä½¿ç”¨æ›´å°çš„å·ç§¯çª—å£ã€‚é™¤äº†æœ€åçš„å·ç§¯å±‚å¤–ï¼Œè¿›ä¸€æ­¥å¢å¤§äº†è¾“å‡ºé€šé“æ•°ã€‚\n",
    "            # å‰ä¸¤ä¸ªå·ç§¯å±‚åä¸ä½¿ç”¨æ± åŒ–å±‚æ¥å‡å°è¾“å…¥çš„é«˜å’Œå®½\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # è¿™é‡Œå…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°æ¯”LeNetä¸­çš„å¤§æ•°å€ã€‚ä½¿ç”¨ä¸¢å¼ƒå±‚æ¥ç¼“è§£è¿‡æ‹Ÿåˆ\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # è¾“å‡ºå±‚ã€‚ç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)  # (batch_szie, channels, height, width)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "237401462039416F8B5874A7DA7FD9F2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEF29AB29F37460C84C492FCE02FEF2D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### è½½å…¥æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8994A770DF884A5D87F60737C50D0A1F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = torch.Size([128, 1, 224, 224]) \n",
      "Y = tensor([4, 8, 3, 0, 3, 2, 7, 7, 8, 4, 8, 5, 1, 1, 9, 1, 3, 5, 2, 7, 8, 1, 2, 4,\n",
      "        5, 1, 8, 9, 4, 8, 1, 2, 3, 9, 7, 2, 1, 9, 1, 6, 2, 0, 1, 7, 4, 9, 4, 5,\n",
      "        5, 9, 8, 5, 5, 4, 1, 1, 9, 1, 0, 4, 6, 5, 0, 0, 5, 5, 5, 5, 2, 8, 8, 7,\n",
      "        1, 4, 9, 7, 9, 4, 4, 6, 7, 8, 8, 1, 8, 2, 7, 6, 4, 1, 3, 7, 9, 2, 8, 1,\n",
      "        3, 5, 8, 2, 7, 1, 3, 3, 6, 5, 6, 7, 4, 1, 4, 1, 3, 7, 3, 4, 0, 5, 8, 1,\n",
      "        3, 7, 8, 6, 0, 2, 6, 5], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# æœ¬å‡½æ•°å·²ä¿å­˜åœ¨d2lzh_pytorchåŒ…ä¸­æ–¹ä¾¿ä»¥åä½¿ç”¨\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='dataset/FashionMNIST2065'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans)  # ç”¨Compose()æŠŠæ‰€æœ‰å˜å½¢æ“ä½œåˆå¹¶ã€‚transæ˜¯ä¸€ä¸ªåˆ—è¡¨\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 128\n",
    "# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, 224)\n",
    "for X, Y in train_iter:\n",
    "    print('X =', X.shape,\n",
    "        '\\nY =', Y.type(torch.int32))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3671547A0D04495B5B1F2ADE856500F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FB33F7F4BEE1486187254524422FDF80",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.2987, train acc 0.888, test acc 0.887, time 195.5 sec\n",
      "epoch 2, loss 0.2732, train acc 0.897, test acc 0.897, time 195.3 sec\n",
      "epoch 3, loss 0.2585, train acc 0.902, test acc 0.898, time 198.5 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 3\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "C40CCB5CDD8E4D3B9A6264B03CBEEB76",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#  ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰\n",
    "VGGï¼šé€šè¿‡é‡å¤ä½¿â½¤ç®€å•çš„åŸºç¡€å—æ¥æ„å»ºæ·±åº¦æ¨¡å‹ã€‚  \n",
    "Block:æ•°ä¸ªç›¸åŒçš„å¡«å……ä¸º1ã€çª—å£å½¢çŠ¶ä¸º$3\\times 3$çš„å·ç§¯å±‚,æ¥ä¸Šä¸€ä¸ªæ­¥å¹…ä¸º2ã€çª—å£å½¢çŠ¶ä¸º$2\\times 2$çš„æœ€å¤§æ± åŒ–å±‚ã€‚(å›¾ä¸­æœ‰è¯¯)  \n",
    "å·ç§¯å±‚ä¿æŒè¾“å…¥çš„é«˜å’Œå®½ä¸å˜ï¼Œè€Œæ± åŒ–å±‚åˆ™å¯¹å…¶å‡åŠã€‚**å› æ­¤æ¯ç»è¿‡ä¸€ä¸ªvgg_blockéƒ½ä¼šä½¿å®½é«˜å‡åŠ**\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6vut7h1.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3D1E7D0AC154E6A99842D587608E870",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### VGG11çš„ç®€å•å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AA4AB087A263436B90B719085FEABC67",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels): #å·ç§¯å±‚ä¸ªæ•°ï¼Œè¾“å…¥é€šé“æ•°ï¼Œè¾“å‡ºé€šé“æ•°\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # è¿™é‡Œä¼šä½¿å®½é«˜å‡åŠ\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3199FD641C1F417FA3C6B65784A20CF2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512)) #æ¯ä¸ªvgg_blockçš„å·ç§¯å±‚ä¸ªæ•°ï¼Œè¾“å…¥é€šé“ï¼Œè¾“å‡ºé€šé“\n",
    "# ç»è¿‡5ä¸ªvgg_block, å®½é«˜ä¼šå‡åŠ5æ¬¡, å˜æˆ 224/32 = 7\n",
    "fc_features = 512 * 7 * 7 # c * w * h\n",
    "fc_hidden_units = 4096 # ä»»æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "08AA6A69F80B4DAC8FA831C6E5C9260B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vgg(conv_arch, fc_features, fc_hidden_units=4096):\n",
    "    net = nn.Sequential()\n",
    "    # å·ç§¯å±‚éƒ¨åˆ†\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # æ¯ç»è¿‡ä¸€ä¸ªvgg_blockéƒ½ä¼šä½¿å®½é«˜å‡åŠ\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    # å…¨è¿æ¥å±‚éƒ¨åˆ†\n",
    "    net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(),\n",
    "                                 nn.Linear(fc_features, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, 10)\n",
    "                                ))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A5FDDE9D6C404D868E3AB5E1731043D9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_block_1 output shape:  torch.Size([1, 64, 112, 112])\n",
      "vgg_block_2 output shape:  torch.Size([1, 128, 56, 56])\n",
      "vgg_block_3 output shape:  torch.Size([1, 256, 28, 28])\n",
      "vgg_block_4 output shape:  torch.Size([1, 512, 14, 14])\n",
      "vgg_block_5 output shape:  torch.Size([1, 512, 7, 7])\n",
      "fc output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "\n",
    "# named_childrenè·å–ä¸€çº§å­æ¨¡å—åŠå…¶åå­—(named_modulesä¼šè¿”å›æ‰€æœ‰å­æ¨¡å—,åŒ…æ‹¬å­æ¨¡å—çš„å­æ¨¡å—)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "40A6F9278D034D4A874189A1F8F52ABF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (vgg_block_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): FlattenLayer()\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ratio = 8\n",
    "small_conv_arch = [(1, 1, 64//ratio), (1, 64//ratio, 128//ratio), (2, 128//ratio, 256//ratio), \n",
    "                   (2, 256//ratio, 512//ratio), (2, 512//ratio, 512//ratio)]\n",
    "net = vgg(small_conv_arch, fc_features // ratio, fc_hidden_units // ratio)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5325FD0A7DB64D43809A660129617282",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.7938, train acc 0.696, test acc 0.867, time 185.1 sec\n",
      "epoch 2, loss 0.3402, train acc 0.877, test acc 0.883, time 183.4 sec\n",
      "epoch 3, loss 0.2886, train acc 0.896, test acc 0.905, time 184.0 sec\n",
      "epoch 4, loss 0.2579, train acc 0.906, test acc 0.907, time 183.4 sec\n",
      "epoch 5, loss 0.2362, train acc 0.913, test acc 0.909, time 185.3 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize\n",
    "# train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7D83E04F316B4D0B933654E2F9FB08B9",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#  ç½‘ç»œä¸­çš„ç½‘ç»œï¼ˆNiNï¼‰ \n",
    "LeNetã€AlexNetå’ŒVGGï¼šå…ˆä»¥ç”±å·ç§¯å±‚æ„æˆçš„æ¨¡å—å……åˆ†æŠ½å– ç©ºé—´ç‰¹å¾ï¼Œå†ä»¥ç”±å…¨è¿æ¥å±‚æ„æˆçš„æ¨¡å—æ¥è¾“å‡ºåˆ†ç±»ç»“æœã€‚  \n",
    "NiNï¼šä¸²è”å¤šä¸ªç”±å·ç§¯å±‚å’Œâ€œå…¨è¿æ¥â€å±‚æ„æˆçš„å°â½¹ç»œæ¥æ„å»ºâ¼€ä¸ªæ·±å±‚â½¹ç»œã€‚  \n",
    "â½¤äº†è¾“å‡ºé€šé“æ•°ç­‰äºæ ‡ç­¾ç±»åˆ«æ•°çš„NiNå—ï¼Œç„¶åä½¿â½¤å…¨å±€å¹³å‡æ± åŒ–å±‚å¯¹æ¯ä¸ªé€šé“ä¸­æ‰€æœ‰å…ƒç´ æ±‚å¹³å‡å¹¶ç›´æ¥â½¤äºåˆ†ç±»ã€‚  \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6u1p5vy.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "**1Ã—1å·ç§¯æ ¸ä½œç”¨**   \n",
    "1.æ”¾ç¼©é€šé“æ•°ï¼šé€šè¿‡æ§åˆ¶å·ç§¯æ ¸çš„æ•°é‡è¾¾åˆ°é€šé“æ•°çš„æ”¾ç¼©ã€‚  \n",
    "2.å¢åŠ éçº¿æ€§ã€‚1Ã—1å·ç§¯æ ¸çš„å·ç§¯è¿‡ç¨‹ç›¸å½“äºå…¨è¿æ¥å±‚çš„è®¡ç®—è¿‡ç¨‹ï¼Œå¹¶ä¸”è¿˜åŠ å…¥äº†éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œä»è€Œå¯ä»¥å¢åŠ ç½‘ç»œçš„éçº¿æ€§ã€‚  \n",
    "3.è®¡ç®—å‚æ•°å°‘   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "88FB988FED1F4CB08417E01A3C560459",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nin_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU())\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AB1A33FE0F1C451F87F390FEC87D334E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# å·²ä¿å­˜åœ¨d2lzh_pytorch\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    # å…¨å±€å¹³å‡æ± åŒ–å±‚å¯é€šè¿‡å°†æ± åŒ–çª—å£å½¢çŠ¶è®¾ç½®æˆè¾“å…¥çš„é«˜å’Œå®½å®ç° (B, C, H, W)ğŸ‘‰(B, C, 1, 1)\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, stride=4, padding=0),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    nn.Dropout(0.5),\n",
    "    # æ ‡ç­¾ç±»åˆ«æ•°æ˜¯10\n",
    "    nin_block(384, 10, kernel_size=3, stride=1, padding=1),\n",
    "    GlobalAvgPool2d(),  # è¾“å‡ºæ˜¯(Batch_size, C, 1, 1)\n",
    "    d2l.FlattenLayer()) # å°†å››ç»´çš„è¾“å‡ºè½¬æˆäºŒç»´çš„è¾“å‡ºï¼Œå…¶å½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "08C2986CBEEF40F98825FC6FF163C572",
    "jupyter": {},
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 output shape:  torch.Size([1, 96, 54, 54])\n",
      "1 output shape:  torch.Size([1, 96, 26, 26])\n",
      "2 output shape:  torch.Size([1, 256, 26, 26])\n",
      "3 output shape:  torch.Size([1, 256, 12, 12])\n",
      "4 output shape:  torch.Size([1, 384, 12, 12])\n",
      "5 output shape:  torch.Size([1, 384, 5, 5])\n",
      "6 output shape:  torch.Size([1, 384, 5, 5])\n",
      "7 output shape:  torch.Size([1, 10, 5, 5])\n",
      "8 output shape:  torch.Size([1, 10, 1, 1])\n",
      "9 output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 1, 224, 224)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DBD61B6A08E1400996DCB60B4B570818",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.1618, train acc 0.560, test acc 0.756, time 261.3 sec\n",
      "epoch 2, loss 0.6451, train acc 0.771, test acc 0.774, time 257.9 sec\n",
      "epoch 3, loss 0.5734, train acc 0.793, test acc 0.803, time 262.4 sec\n",
      "epoch 4, loss 0.5227, train acc 0.809, test acc 0.812, time 258.2 sec\n",
      "epoch 5, loss 0.4828, train acc 0.823, test acc 0.821, time 258.1 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize\n",
    "\n",
    "lr, num_epochs = 0.002, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE1E233B008843DEB6E582ECFEE65617",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "NiNé‡å¤ä½¿â½¤ç”±å·ç§¯å±‚å’Œä»£æ›¿å…¨è¿æ¥å±‚çš„1Ã—1å·ç§¯å±‚æ„æˆçš„NiNå—æ¥æ„å»ºæ·±å±‚â½¹ç»œã€‚  \n",
    "NiNå»é™¤äº†å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆçš„å…¨è¿æ¥è¾“å‡ºå±‚ï¼Œè€Œæ˜¯å°†å…¶æ›¿æ¢æˆè¾“å‡ºé€šé“æ•°ç­‰äºæ ‡ç­¾ç±»åˆ«æ•° çš„NiNå—å’Œå…¨å±€å¹³å‡æ± åŒ–å±‚ã€‚   \n",
    "NiNçš„ä»¥ä¸Šè®¾è®¡æ€æƒ³å½±å“äº†åâ¾¯â¼€ç³»åˆ—å·ç§¯ç¥ç»â½¹ç»œçš„è®¾è®¡ã€‚  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7886126F79424D75863FB4B09025CE40",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# GoogLeNet\n",
    "1. ç”±InceptionåŸºç¡€å—ç»„æˆã€‚  \n",
    "2. Inceptionå—ç›¸å½“äºâ¼€ä¸ªæœ‰4æ¡çº¿è·¯çš„â¼¦â½¹ç»œã€‚å®ƒé€šè¿‡ä¸åŒçª—å£å½¢çŠ¶çš„å·ç§¯å±‚å’Œæœ€â¼¤æ± åŒ–å±‚æ¥å¹¶â¾æŠ½å–ä¿¡æ¯ï¼Œå¹¶ä½¿â½¤1Ã—1å·ç§¯å±‚å‡å°‘é€šé“æ•°ä»è€Œé™ä½æ¨¡å‹å¤æ‚åº¦ã€‚   \n",
    "3. å¯ä»¥â¾ƒå®šä¹‰çš„è¶…å‚æ•°æ˜¯æ¯ä¸ªå±‚çš„è¾“å‡ºé€šé“æ•°ï¼Œæˆ‘ä»¬ä»¥æ­¤æ¥æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚ \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6uortw.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E9CBC745630F489CB69A0001B076F199",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1 - c4ä¸ºæ¯æ¡çº¿è·¯é‡Œçš„å±‚çš„è¾“å‡ºé€šé“æ•°, å››ä¸ªçº¿è·¯å‡ä¸æ”¹å˜é•¿å’Œå®½\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # çº¿è·¯1ï¼Œå•1 x 1å·ç§¯å±‚\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # çº¿è·¯2ï¼Œ1 x 1å·ç§¯å±‚åæ¥3 x 3å·ç§¯å±‚\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # çº¿è·¯3ï¼Œ1 x 1å·ç§¯å±‚åæ¥5 x 5å·ç§¯å±‚\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # çº¿è·¯4ï¼Œ3 x 3æœ€å¤§æ± åŒ–å±‚åæ¥1 x 1å·ç§¯å±‚\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # åœ¨é€šé“ç»´ä¸Šè¿ç»“è¾“å‡º"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E4C63967592040D9BD9D31D7078999DC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### GoogLeNetæ¨¡å‹\n",
    "å®Œæ•´æ¨¡å‹ç»“æ„  \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6x0fyyn.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "566939FB07C646D380806E2CA941FD85",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([1, 64, 24, 24])\n",
      "output shape:  torch.Size([1, 192, 12, 12])\n",
      "output shape:  torch.Size([1, 480, 6, 6])\n",
      "output shape:  torch.Size([1, 832, 3, 3])\n",
      "output shape:  torch.Size([1, 1024, 1, 1])\n",
      "output shape:  torch.Size([1, 1024])\n",
      "output shape:  torch.Size([1, 10])\n",
      "training on  cuda\n",
      "epoch 1, loss 1.0494, train acc 0.599, test acc 0.818, time 254.6 sec\n",
      "epoch 2, loss 0.4263, train acc 0.844, test acc 0.855, time 244.4 sec\n",
      "epoch 3, loss 0.3495, train acc 0.870, test acc 0.876, time 242.4 sec\n",
      "epoch 4, loss 0.3027, train acc 0.889, test acc 0.885, time 243.8 sec\n",
      "epoch 5, loss 0.2672, train acc 0.902, test acc 0.898, time 238.4 sec\n"
     ]
    }
   ],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   d2l.GlobalAvgPool2d())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, \n",
    "                    d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "\n",
    "for blk in net.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "    \n",
    "batchsize = 64\n",
    "# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96, root='dataset/FashionMNIST2065')\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch1-gpu]",
   "language": "python",
   "name": "conda-env-pytorch1-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
