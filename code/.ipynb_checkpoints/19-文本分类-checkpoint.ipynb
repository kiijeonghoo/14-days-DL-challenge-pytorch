{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_on4eyh2",
    "id": "9E73B21214794A1B8F92AF2169A6F409",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 文本情感分类\n",
    "\n",
    "文本分类是自然语言处理的一个常见任务，它把一段不定长的文本序列变换为文本的类别。本节关注它的一个子问题：使用文本情感分类来分析文本作者的情绪。这个问题也叫情感分析，并有着广泛的应用。\n",
    "\n",
    "同搜索近义词和类比词一样，文本分类也属于词嵌入的下游应用。在本节中，我们将应用预训练的词向量和含多个隐藏层的双向循环神经网络与卷积神经网络，来判断一段不定长的文本序列中包含的是正面还是负面的情绪。后续内容将从以下几个方面展开：\n",
    "\n",
    "1. 文本情感分类数据集\n",
    "2. 使用循环神经网络进行情感分类\n",
    "3. 使用卷积神经网络进行情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "graffitiCellId": "id_qpkl0v3",
    "id": "4C34DE8574664EBC876799AFFD97FACC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_75c1s0z",
    "id": "ECA9EC64CB6B4C0C8CCDB65ACD18D2BE",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 文本情感分类数据\n",
    "\n",
    "我们使用[斯坦福的IMDb数据集（Stanford’s Large Movie Review Dataset）](http://ai.stanford.edu/~amaas/data/sentiment/)作为文本情感分类的数据集。\n",
    "\n",
    "### 读取数据\n",
    "\n",
    "数据集文件夹结构：\n",
    "\n",
    "```\n",
    "| aclImdb_v1\n",
    "    | train\n",
    "    |   | pos\n",
    "    |   |   | 0_9.txt  \n",
    "    |   |   | 1_7.txt\n",
    "    |   |   | ...\n",
    "    |   | neg\n",
    "    |   |   | 0_3.txt\n",
    "    |   |   | 1_1.txt\n",
    "    |   | ...\n",
    "    | test\n",
    "    |   | pos\n",
    "    |   | neg\n",
    "    |   | ...\n",
    "    | ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "graffitiCellId": "id_nxrjw92",
    "id": "2D650272040243AA8AC04AA8BCC96645",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 8449.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 8651.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 8050.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 8389.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t dog days is one of most accurate films i've ever seen describing life in modern cities. it's very ha\n",
      "1 \t anyone who doesn't like this film is one who is afraid to explore his or her own demons. this film d\n",
      "1 \t after having read two or three negative reviews on the main page of imdb for \"pushing daisies\", and \n",
      "1 \t i think this show is definitely the greatest show. jessica alba does such a great job in it. michael\n",
      "0 \t this film limps from self indulgent moment to self indulgent moment, promising to develop into somet\n"
     ]
    }
   ],
   "source": [
    "def read_imdb(folder='train', data_root=\"../dataset/IMDB2578/aclImdb_v1\"):\n",
    "    data = []\n",
    "    for label in ['pos', 'neg']:\n",
    "        folder_name = os.path.join(data_root, folder, label)\n",
    "        for file in tqdm(os.listdir(folder_name)):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '').lower()\n",
    "                data.append([review, 1 if label == 'pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "DATA_ROOT = \"../dataset/IMDB2578/\"\n",
    "data_root = os.path.join(DATA_ROOT, \"aclImdb_v1\")\n",
    "train_data, test_data = read_imdb('train', data_root), read_imdb('test', data_root)\n",
    "\n",
    "# 打印训练数据中的前五个sample\n",
    "for sample in train_data[:5]:\n",
    "    print(sample[1], '\\t', sample[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_q12pdj4",
    "id": "27D596E884AD48778032BE5876EA56C7",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 预处理数据\n",
    "\n",
    "读取数据后，我们先根据文本的格式进行单词的切分，再利用 [`torchtext.vocab.Vocab`](https://torchtext.readthedocs.io/en/latest/vocab.html#vocab) 创建词典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "graffitiCellId": "id_f6u98c3",
    "id": "501A5FC9F17D49B084DE9C15B04233A3",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in vocab: 46152\n"
     ]
    }
   ],
   "source": [
    "def get_tokenized_imdb(data):\n",
    "    '''\n",
    "    @params:\n",
    "        data: 数据的列表，列表中的每个元素为 [文本字符串，0/1标签] 二元组\n",
    "    @return: 切分词后的文本的列表，列表中的每个元素为切分后的词序列\n",
    "    '''\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(' ')]\n",
    "    \n",
    "    return [tokenizer(review) for review, _ in data]\n",
    "\n",
    "def get_vocab_imdb(data):\n",
    "    '''\n",
    "    @params:\n",
    "        data: 同上\n",
    "    @return: 数据集上的词典，Vocab 的实例（freqs, stoi, itos）\n",
    "    '''\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return Vocab.Vocab(counter, min_freq=5)\n",
    "\n",
    "vocab = get_vocab_imdb(train_data)\n",
    "print('# words in vocab:', len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_9s26xhr",
    "id": "B6CDF2CC978D48F980E835392BAC8CF0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "词典和词语的索引创建好后，就可以将数据集的文本从字符串的形式转换为单词下标序列的形式，以待之后的使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "graffitiCellId": "id_3ejykvx",
    "id": "B8BDA6B5EE364F538022F97E8A1114FC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_imdb(data, vocab):\n",
    "    '''\n",
    "    @params:\n",
    "        data: 同上，原始的读入数据\n",
    "        vocab: 训练集上生成的词典\n",
    "    @return:\n",
    "        features: 单词下标序列，形状为 (n, max_l) 的整数张量\n",
    "        labels: 情感标签，形状为 (n,) 的0/1整数张量\n",
    "    '''\n",
    "    max_l = 500  # 将每条评论通过截断或者补0，使得长度变成500\n",
    "\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\n",
    "\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    features = torch.tensor([pad([vocab.stoi[word] for word in sentence]) for sentence in tokenized_data])\n",
    "    labels = torch.tensor([score for _, score in data])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_yge4ncq",
    "id": "D4189672985F4DA781725897C3395EBB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 创建数据迭代器\n",
    "\n",
    "利用 [`torch.utils.data.TensorDataset`](https://pytorch.org/docs/stable/data.html?highlight=tensor%20dataset#torch.utils.data.TensorDataset)，可以创建 PyTorch 格式的数据集，从而创建数据迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "graffitiCellId": "id_q2o053r",
    "id": "46970B8D972042009CC3393C59BCD4B6",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "#batches: 391\n"
     ]
    }
   ],
   "source": [
    "train_set = Data.TensorDataset(*preprocess_imdb(train_data, vocab))\n",
    "test_set = Data.TensorDataset(*preprocess_imdb(test_data, vocab))\n",
    "\n",
    "# 上面的代码等价于下面的注释代码\n",
    "# train_features, train_labels = preprocess_imdb(train_data, vocab)\n",
    "# test_features, test_labels = preprocess_imdb(test_data, vocab)\n",
    "# train_set = Data.TensorDataset(train_features, train_labels)\n",
    "# test_set = Data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "# len(train_set) = features.shape[0] or labels.shape[0]\n",
    "# train_set[index] = (features[index], labels[index])\n",
    "\n",
    "batch_size = 64\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "test_iter = Data.DataLoader(test_set, batch_size)\n",
    "\n",
    "for X, y in train_iter:\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    break\n",
    "print('#batches:', len(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_uu3a646",
    "id": "E5DAD388C64B49FF86DA61D202D5A104",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 使用循环神经网络\n",
    "\n",
    "### 双向循环神经网络\n",
    "\n",
    "在[“双向循环神经网络”](https://zh.d2l.ai/chapter_recurrent-neural-networks/bi-rnn.html)一节中，我们介绍了其模型与前向计算的公式，这里简单回顾一下：\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mnobct47.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mo6okdnp.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "\n",
    "给定输入序列 $\\{\\boldsymbol{X}_1,\\boldsymbol{X}_2,\\dots,\\boldsymbol{X}_T\\}$，其中 $\\boldsymbol{X}_t\\in\\mathbb{R}^{n\\times d}$ 为时间步（批量大小为 $n$，输入维度为 $d$）。在双向循环神经网络的架构中，设时间步 $t$ 上的正向隐藏状态为 $\\overrightarrow{\\boldsymbol{H}}_{t} \\in \\mathbb{R}^{n \\times h}$ （正向隐藏状态维度为 $h$），反向隐藏状态为 $\\overleftarrow{\\boldsymbol{H}}_{t} \\in \\mathbb{R}^{n \\times h}$ （反向隐藏状态维度为 $h$）。我们可以分别计算正向隐藏状态和反向隐藏状态：\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\overrightarrow{\\boldsymbol{H}}_{t}=\\phi\\left(\\boldsymbol{X}_{t} \\boldsymbol{W}_{x h}^{(f)}+\\overrightarrow{\\boldsymbol{H}}_{t-1} \\boldsymbol{W}_{h h}^{(f)}+\\boldsymbol{b}_{h}^{(f)}\\right)\\\\\n",
    "&\\overleftarrow{\\boldsymbol{H}}_{t}=\\phi\\left(\\boldsymbol{X}_{t} \\boldsymbol{W}_{x h}^{(b)}+\\overleftarrow{\\boldsymbol{H}}_{t+1} \\boldsymbol{W}_{h h}^{(b)}+\\boldsymbol{b}_{h}^{(b)}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "其中权重 $\\boldsymbol{W}_{x h}^{(f)} \\in \\mathbb{R}^{d \\times h}, \\boldsymbol{W}_{h h}^{(f)} \\in \\mathbb{R}^{h \\times h}, \\boldsymbol{W}_{x h}^{(b)} \\in \\mathbb{R}^{d \\times h}, \\boldsymbol{W}_{h h}^{(b)} \\in \\mathbb{R}^{h \\times h}$ 和偏差 $\\boldsymbol{b}_{h}^{(f)} \\in \\mathbb{R}^{1 \\times h}, \\boldsymbol{b}_{h}^{(b)} \\in \\mathbb{R}^{1 \\times h}$ 均为模型参数，$\\phi$ 为隐藏层激活函数。\n",
    "\n",
    "然后我们连结两个方向的隐藏状态 $\\overrightarrow{\\boldsymbol{H}}_{t}$ 和 $\\overleftarrow{\\boldsymbol{H}}_{t}$ 来得到隐藏状态 $\\boldsymbol{H}_{t} \\in \\mathbb{R}^{n \\times 2 h}$，并将其输入到输出层。输出层计算输出 $\\boldsymbol{O}_{t} \\in \\mathbb{R}^{n \\times q}$（输出维度为 $q$）：\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{O}_{t}=\\boldsymbol{H}_{t} \\boldsymbol{W}_{h q}+\\boldsymbol{b}_{q}\n",
    "$$\n",
    "\n",
    "\n",
    "其中权重 $\\boldsymbol{W}_{h q} \\in \\mathbb{R}^{2 h \\times q}$ 和偏差 $\\boldsymbol{b}_{q} \\in \\mathbb{R}^{1 \\times q}$ 为输出层的模型参数。不同方向上的隐藏单元维度也可以不同。\n",
    "\n",
    "利用 [`torch.nn.RNN`](https://pytorch.org/docs/stable/nn.html?highlight=rnn#torch.nn.RNN) 或 [`torch.nn.LSTM`](https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) 模组，我们可以很方便地实现双向循环神经网络，下面是以 LSTM 为例的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "graffitiCellId": "id_put7k6i",
    "id": "3F85195C090D49B8A78A951C4CD7076B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, num_hiddens, num_layers):\n",
    "        '''\n",
    "        @params:\n",
    "            vocab: 在数据集上创建的词典，用于获取词典大小\n",
    "            embed_size: 嵌入维度大小\n",
    "            num_hiddens: 隐藏状态维度大小\n",
    "            num_layers: 隐藏层个数\n",
    "        '''\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        \n",
    "        # encoder-decoder framework\n",
    "        # bidirectional设为True即得到双向循环神经网络\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=num_hiddens, num_layers=num_layers, bidirectional=True)\n",
    "        self.decoder = nn.Linear(4*num_hiddens, 2) # 初始时间步和最终时间步的隐藏状态作为全连接层输入\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        @params:\n",
    "            inputs: 词语下标序列，形状为 (batch_size, seq_len) 的整数张量\n",
    "        @return:\n",
    "            outs: 对文本情感的预测，形状为 (batch_size, 2) 的张量\n",
    "        '''\n",
    "        # 因为LSTM需要将序列长度(seq_len)作为第一维，所以需要将输入转置\n",
    "        embeddings = self.embedding(inputs.permute(1, 0)) # (seq_len, batch_size, d)\n",
    "        # rnn.LSTM 返回输出、隐藏状态和记忆单元，格式如 outputs, (h, c)\n",
    "        outputs, _ = self.encoder(embeddings) # (seq_len, batch_size, 2*h)\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), -1) # (batch_size, 4*h)\n",
    "        outs = self.decoder(encoding) # (batch_size, 2)\n",
    "        return outs\n",
    "\n",
    "embed_size, num_hiddens, num_layers = 100, 100, 2\n",
    "net = BiRNN(vocab, embed_size, num_hiddens, num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ksnuxvt",
    "id": "331B28609E2F4FCD81A30F5E665DB7EF",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 加载预训练的词向量\n",
    "\n",
    "由于预训练词向量的词典及词语索引与我们使用的数据集并不相同，所以需要根据目前的词典及索引的顺序来加载预训练词向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████▉| 399649/400000 [00:40<00:00, 14769.62it/s]"
     ]
    }
   ],
   "source": [
    "cache_dir = \"../dataset/GloVe6B5429\"\n",
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46152"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400000, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "graffitiCellId": "id_1x32tei",
    "id": "E1E904AB724240589BAF01DA77485092",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21202 oov words.\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_embedding(words, pretrained_vocab):\n",
    "    '''\n",
    "    @params:\n",
    "        words: 需要加载词向量的词语列表，以 itos (index to string) 的词典形式给出\n",
    "        pretrained_vocab: 预训练词向量\n",
    "    @return:\n",
    "        embed: 加载到的词向量\n",
    "    '''\n",
    "    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0]) # 初始化为0\n",
    "    oov_count = 0 # out of vocabulary\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            idx = pretrained_vocab.stoi[word]\n",
    "            embed[i, :] = pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count += 1\n",
    "    if oov_count > 0:\n",
    "        print(\"There are %d oov words.\" % oov_count)\n",
    "    return embed\n",
    "\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "net.embedding.weight.requires_grad = False # 直接加载预训练好的, 所以不需要更新它"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_rfun1jp",
    "id": "6C1065F141F041D68C843ECD13DB5193",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 训练模型\n",
    "\n",
    "训练时可以调用之前编写的 `train` 及 `evaluate_accuracy` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "graffitiCellId": "id_jv4ye1d",
    "id": "6E7F2873372E42F0AD93F544A6DEEBDC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        device = list(net.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval()\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else:\n",
    "                if('is_training' in net.__code__.co_varnames):\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y) \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_jt55knm",
    "id": "3E29E40F14214A51B947A99BACBA7094",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "由于嵌入层的参数是不需要在训练过程中被更新的，所以我们利用 `filter` 函数和 `lambda` 表达式来过滤掉模型中不需要更新参数的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "graffitiCellId": "id_qx54klj",
    "id": "AB49B88221294D6283A876AFA0A6700C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.5757, train acc 0.666, test acc 0.835, time 97.3 sec\n",
      "epoch 2, loss 0.1797, train acc 0.844, test acc 0.846, time 92.8 sec\n",
      "epoch 3, loss 0.1010, train acc 0.872, test acc 0.855, time 92.9 sec\n",
      "epoch 4, loss 0.0655, train acc 0.892, test acc 0.869, time 93.9 sec\n",
      "epoch 5, loss 0.0457, train acc 0.907, test acc 0.859, time 94.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_yb7fec7",
    "id": "AA2AF53E215F4550ABB1903215DE743D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "training on  cuda\n",
    "100%|█████████▉| 398892/400000 [00:40<00:00, 18148.73it/s]\n",
    "epoch 1, loss 0.6206, train acc 0.631, test acc 0.798, time 41.7 sec\n",
    "epoch 2, loss 0.2079, train acc 0.813, test acc 0.819, time 42.1 sec\n",
    "epoch 3, loss 0.1186, train acc 0.843, test acc 0.847, time 40.8 sec\n",
    "epoch 4, loss 0.0777, train acc 0.869, test acc 0.854, time 41.2 sec\n",
    "epoch 5, loss 0.0544, train acc 0.887, test acc 0.861, time 41.8 sec\n",
    "```\n",
    "\n",
    "*注：由于本地CPU上训练时间过长，故只截取了运行的结果，后同。大家可以自行在网站上训练。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_mxbji9v",
    "id": "E92D6D9EC8D84D998AFF2BC517515378",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "graffitiCellId": "id_rtedxzv",
    "id": "61A4F01E8A0C434CB6A193D540C58366",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(net, vocab, sentence):\n",
    "    '''\n",
    "    @params：\n",
    "        net: 训练好的模型\n",
    "        vocab: 在该数据集上创建的词典，用于将给定的单词序转换为单词下标的序列，从而输入模型\n",
    "        sentence: 需要分析情感的文本，以单词序列的形式给出\n",
    "    @return: 预测的结果，positive 为正面情绪文本，negative 为负面情绪文本\n",
    "    '''\n",
    "    device = list(net.parameters())[0].device # 读取模型所在的环境\n",
    "    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n",
    "    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n",
    "    return 'positive' if label.item() == 1 else 'negative'\n",
    "\n",
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "graffitiCellId": "id_ci26bbu",
    "id": "F1AF9815A91C45C4B87B5641F632C949",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_h9301aq",
    "id": "467567D6536D47B887CF000BF0B9E7B1",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 使用卷积神经网络\n",
    "\n",
    "### 一维卷积层\n",
    "\n",
    "在介绍模型前我们先来解释一维卷积层的工作原理。与二维卷积层一样，一维卷积层使用一维的互相关运算。在一维互相关运算中，卷积窗口从输入数组的最左方开始，按从左往右的顺序，依次在输入数组上滑动。当卷积窗口滑动到某一位置时，窗口中的输入子数组与核数组按元素相乘并求和，得到输出数组中相应位置的元素。如图所示，输入是一个宽为 7 的一维数组，核数组的宽为 2。可以看到输出的宽度为 7−2+1=6，且第一个元素是由输入的最左边的宽为 2 的子数组与核数组按元素相乘后再相加得到的：0×1+1×2=2。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mo8qs7dc.png?imageView2/0/w/960/h/960)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "graffitiCellId": "id_vf1wafb",
    "id": "F25448093E6340D181FE33A95E9F6FFB",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  5.,  8., 11., 14., 17.])\n"
     ]
    }
   ],
   "source": [
    "def corr1d(X, K):\n",
    "    '''\n",
    "    @params:\n",
    "        X: 输入，形状为 (seq_len,) 的张量\n",
    "        K: 卷积核，形状为 (w,) 的张量\n",
    "    @return:\n",
    "        Y: 输出，形状为 (seq_len - w + 1,) 的张量\n",
    "    '''\n",
    "    w = K.shape[0] # 卷积窗口宽度\n",
    "    Y = torch.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]): # 滑动窗口\n",
    "        Y[i] = (X[i: i + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "X, K = torch.tensor([0, 1, 2, 3, 4, 5, 6]), torch.tensor([1, 2])\n",
    "print(corr1d(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_e67uju2",
    "id": "6AA00E61C69A4E42865B78FEC87E757D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "多输入通道的一维互相关运算也与多输入通道的二维互相关运算类似：在每个通道上，将核与相应的输入做一维互相关运算，并将通道之间的结果相加得到输出结果。下图展示了含 3 个输入通道的一维互相关运算，其中阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：0×1+1×2+1×3+2×4+2×(−1)+3×(−3)=2。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5moaawczv.png?imageView2/0/w/960/h/960)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "graffitiCellId": "id_480pc9k",
    "id": "4E0F6D6AEB7344F080E9D8B0BFECFAD7",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  8., 14., 20., 26., 32.])\n"
     ]
    }
   ],
   "source": [
    "def corr1d_multi_in(X, K):\n",
    "    # 首先沿着X和K的通道维遍历并计算一维互相关结果。然后将所有结果堆叠起来沿第0维累加\n",
    "    return torch.stack([corr1d(x, k) for x, k in zip(X, K)]).sum(dim=0)\n",
    "    # [corr1d(X[i], K[i]) for i in range(X.shape[0])]\n",
    "\n",
    "X = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = torch.tensor([[1, 2], [3, 4], [-1, -3]])\n",
    "print(corr1d_multi_in(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_owwaz9l",
    "id": "FE1904E0DCC34AEB939DFE0B911985A6",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "由二维互相关运算的定义可知，多输入通道的一维互相关运算可以看作单输入通道的二维互相关运算。如图所示，我们也可以将图中多输入通道的一维互相关运算以等价的单输入通道的二维互相关运算呈现。这里核的高等于输入的高。图中的阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：2×(−1)+3×(−3)+1×3+2×4+0×1+1×2=2。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5moav6ue3.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "*注：反之仅当二维卷积核的高度等于输入的高度时才成立。*\n",
    "\n",
    "之前的例子中输出都只有一个通道。我们在[“多输入通道和多输出通道”](https://zh.d2l.ai/chapter_convolutional-neural-networks/channels.html)一节中介绍了如何在二维卷积层中指定多个输出通道。类似地，我们也可以在一维卷积层指定多个输出通道，从而拓展卷积层中的模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_sp8o70s",
    "id": "64F1FB72318E45CC8EC2E974216BA59D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 时序最大池化层\n",
    "\n",
    "类似地，我们有一维池化层。TextCNN 中使用的时序最大池化（max-over-time pooling）层实际上对应一维全局最大池化层：假设输入包含多个通道，各通道由不同时间步上的数值组成，各通道的输出即该通道所有时间步中最大的数值。因此，时序最大池化层的输入在各个通道上的时间步数可以不同。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5mobv3kol.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "*注：自然语言中还有一些其他的池化操作，可参考这篇[博文](https://blog.csdn.net/malefactor/article/details/51078135)。*\n",
    "\n",
    "为提升计算性能，我们常常将不同长度的时序样本组成一个小批量，并通过在较短序列后附加特殊字符（如0）令批量中各时序样本长度相同。这些人为添加的特殊字符当然是无意义的。由于时序最大池化的主要目的是抓取时序中最重要的特征，它通常能使模型不受人为添加字符的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "graffitiCellId": "id_3r1xhqh",
    "id": "CB9416F229DB46038A3FC9AD670096E3",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        @params:\n",
    "            x: 输入，形状为 (batch_size, n_channels, seq_len) 的张量\n",
    "        @return: 时序最大池化后的结果，形状为 (batch_size, n_channels, 1) 的张量\n",
    "        '''\n",
    "        return F.max_pool1d(x, kernel_size=x.shape[2]) # kenerl_size=seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_lhc1gs8",
    "id": "D697DE419B87437780D66FB3DD6D6C89",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### TextCNN 模型\n",
    "\n",
    "TextCNN 模型主要使用了一维卷积层和时序最大池化层。假设输入的文本序列由 $n$ 个词组成，每个词用 $d$ 维的词向量表示。那么输入样本的宽为 $n$，输入通道数为 $d$。TextCNN 的计算主要分为以下几步。\n",
    "\n",
    "1. 定义多个一维卷积核，并使用这些卷积核对输入分别做卷积计算。宽度不同的卷积核可能会捕捉到不同个数的相邻词的相关性。\n",
    "2. 对输出的所有通道分别做时序最大池化，再将这些通道的池化输出值连结为向量。\n",
    "3. 通过全连接层将连结后的向量变换为有关各类别的输出。这一步可以使用丢弃层应对过拟合。\n",
    "\n",
    "下图用一个例子解释了 TextCNN 的设计。这里的输入是一个有 11 个词的句子，每个词用 6 维词向量表示。因此输入序列的宽为 11，输入通道数为 6。给定 2 个一维卷积核，核宽分别为 2 和 4，输出通道数分别设为 4 和 5。因此，一维卷积计算后，4 个输出通道的宽为 11−2+1=10，而其他 5 个通道的宽为 11−4+1=8。尽管每个通道的宽不同，我们依然可以对各个通道做时序最大池化，并将 9 个通道的池化输出连结成一个 9 维向量。最终，使用全连接将 9 维向量变换为 2 维输出，即正面情感和负面情感的预测。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5modgownf.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "下面我们来实现 TextCNN 模型。与上一节相比，除了用一维卷积层替换循环神经网络外，这里我们还使用了两个嵌入层，一个的权重固定，另一个则参与训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "graffitiCellId": "id_9mqnlf7",
    "id": "43E465F855D841EEA2ABD3F0B16F6429",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, kernel_sizes, num_channels):\n",
    "        '''\n",
    "        @params:\n",
    "            vocab: 在数据集上创建的词典，用于获取词典大小\n",
    "            embed_size: 嵌入维度大小\n",
    "            kernel_sizes: 卷积核大小列表\n",
    "            num_channels: 卷积通道数列表\n",
    "        '''\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size) # 参与训练的嵌入层\n",
    "        self.constant_embedding = nn.Embedding(len(vocab), embed_size) # 不参与训练的嵌入层\n",
    "        \n",
    "        self.pool = GlobalMaxPool1d() # 时序最大池化层没有权重，所以可以共用一个实例\n",
    "        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, out_channels = c, kernel_size = k))\n",
    "\n",
    "        self.decoder = nn.Linear(sum(num_channels), 2)\n",
    "        self.dropout = nn.Dropout(0.5) # 丢弃层用于防止过拟合\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        @params:\n",
    "            inputs: 词语下标序列，形状为 (batch_size, seq_len) 的整数张量\n",
    "        @return:\n",
    "            outputs: 对文本情感的预测，形状为 (batch_size, 2) 的张量\n",
    "        '''\n",
    "        embeddings = torch.cat((self.embedding(inputs), \n",
    "                                self.constant_embedding(inputs)), dim=2) # (batch_size, seq_len, 2*embed_size)\n",
    "        # 根据一维卷积层要求的输入格式，需要将张量进行转置\n",
    "        embeddings = embeddings.permute(0, 2, 1) # (batch_size, 2*embed_size, seq_len)  通道数为 2*embed_size\n",
    "        \n",
    "        encoding = torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        # encoding = []\n",
    "        # for conv in self.convs:\n",
    "        #     out = conv(embeddings) # (batch_size, out_channels, seq_len-kernel_size+1)\n",
    "        #     out = self.pool(F.relu(out)) # (batch_size, out_channels, 1)\n",
    "        #     encoding.append(out.squeeze(-1)) # (batch_size, out_channels)\n",
    "        # encoding = torch.cat(encoding) # (batch_size, out_channels_sum)\n",
    "        \n",
    "        # 应用丢弃法后使用全连接层得到输出\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs\n",
    "\n",
    "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_leupmp8",
    "id": "374844FBE56B43668639A9C07D0E2DD0",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 训练并评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "graffitiCellId": "id_g74v4mq",
    "id": "BC1674BE51704FBA9F46925EE338B813",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.6357, train acc 0.664, test acc 0.800, time 58.0 sec\n",
      "epoch 2, loss 0.2403, train acc 0.769, test acc 0.835, time 57.6 sec\n",
      "epoch 3, loss 0.1349, train acc 0.820, test acc 0.854, time 59.1 sec\n",
      "epoch 4, loss 0.0817, train acc 0.859, test acc 0.863, time 59.4 sec\n",
      "epoch 5, loss 0.0505, train acc 0.897, test acc 0.868, time 58.1 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train(train_iter, test_iter, net, loss, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_b5cbyuk",
    "id": "8BEB86488C464EB09629F94A5198DCDB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "training on  cuda\n",
    "epoch 1, loss 0.6314, train acc 0.666, test acc 0.803, time 15.9 sec\n",
    "epoch 2, loss 0.2416, train acc 0.766, test acc 0.807, time 15.9 sec\n",
    "epoch 3, loss 0.1330, train acc 0.821, test acc 0.849, time 15.9 sec\n",
    "epoch 4, loss 0.0825, train acc 0.858, test acc 0.860, time 16.0 sec\n",
    "epoch 5, loss 0.0494, train acc 0.898, test acc 0.865, time 15.9 sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "graffitiCellId": "id_me4atgv",
    "id": "4817955A29B1426BA9AF6B9493EC83F0",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "graffitiCellId": "id_6qea9rq",
    "id": "EF6C2C490A2C49DC8F49794FB5BCD7ED",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch1-gpu]",
   "language": "python",
   "name": "conda-env-pytorch1-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
